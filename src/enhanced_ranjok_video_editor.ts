import { jianYingMCP, JianYingMCPResponse, DraftConfig, TrackConfig, VideoSegmentConfig, AudioSegmentConfig, TextSegmentConfig, EffectConfig } from './jianying_mcp_adapter.js';

interface VideoClip {
  id: string;
  filePath: string;
  duration: number;
  startTime: number;
  endTime: number;
  metadata: {
    width: number;
    height: number;
    fps: number;
    bitrate: number;
  };
}

interface VideoEffect {
  type: 'transition' | 'filter' | 'text' | 'music' | 'voiceover' | 'animation';
  id: string;
  timing: { start: number; duration: number };
  properties: Record<string, any>;
}

interface EnhancedAutoVideoConfig {
  title: string;
  style: 'vlog' | 'business' | 'education' | 'entertainment' | 'social';
  targetDuration: number;
  aspectRatio: '16:9' | '9:16' | '1:1';
  sourceClips: string[];
  musicStyle?: 'upbeat' | 'calm' | 'dramatic' | 'corporate';
  includeCaptions?: boolean;
  includeIntro?: boolean;
  includeOutro?: boolean;
  exportPath?: string;
}

interface JianYingWorkflowResult {
  success: boolean;
  draftId?: string;
  trackIds: Record<string, string>; // video_1, audio_1, text_1 ç­‰
  segmentIds: string[];
  exportPath?: string;
  timeline: VideoClip[];
  effects: VideoEffect[];
  estimatedDuration: number;
  workflowSteps: Array<{ step: string; success: boolean; result?: any; error?: string }>;
}

class EnhancedRanJokVideoEditor {
  private templates: Record<string, VideoEffect[]> = {};
  private musicLibrary: Record<string, string[]> = {};

  constructor() {
    this.initializeTemplates();
    this.initializeMusicLibrary();
  }

  private initializeTemplates() {
    // Vlog é£æ ¼æ¨¡æ¿
    this.templates.vlog = [
      {
        type: 'animation',
        id: 'fade-in',
        timing: { start: 0, duration: 1 },
        properties: { type: 'æ·¡å…¥æ·¡å‡º', direction: 'in' }
      },
      {
        type: 'text',
        id: 'title-overlay',
        timing: { start: 2, duration: 3 },
        properties: {
          text: '{{title}}',
          fontSize: 48,
          color: '#ffffff',
          position: 'center',
          animation: 'å¼¹è·³æ•ˆæœ'
        }
      },
      {
        type: 'transition',
        id: 'quick-cut',
        timing: { start: 0, duration: 0.5 },
        properties: { type: 'æ»‘åŠ¨åˆ‡æ¢', style: 'quick' }
      }
    ];

    // å•†åŠ¡é£æ ¼æ¨¡æ¿
    this.templates.business = [
      {
        type: 'text',
        id: 'professional-title',
        timing: { start: 1, duration: 4 },
        properties: {
          text: '{{title}}',
          fontSize: 42,
          color: '#2c3e50',
          position: 'center',
          animation: 'æ»‘åŠ¨è¿›å…¥'
        }
      },
      {
        type: 'transition',
        id: 'professional-wipe',
        timing: { start: 0, duration: 0.8 },
        properties: { type: 'é¡µé¢ç¿»è½¬', direction: 'left' }
      },
      {
        type: 'filter',
        id: 'corporate-look',
        timing: { start: 0, duration: -1 }, // -1 è¡¨ç¤ºæ•´ä¸ªè§†é¢‘
        properties: { type: 'é«˜å¯¹æ¯”åº¦', strength: 0.7 }
      }
    ];

    // æ•™è‚²é£æ ¼æ¨¡æ¿
    this.templates.education = [
      {
        type: 'text',
        id: 'lesson-title',
        timing: { start: 0.5, duration: 2.5 },
        properties: {
          text: 'ç¬¬{{index}}è¯¾: {{title}}',
          fontSize: 36,
          color: '#3498db',
          position: 'top',
          animation: 'ç¼©æ”¾å‡ºç°'
        }
      },
      {
        type: 'filter',
        id: 'education-clarity',
        timing: { start: 0, duration: -1 },
        properties: { type: 'æš–è‰²è°ƒ', strength: 0.3 }
      }
    ];

    // å¨±ä¹é£æ ¼æ¨¡æ¿
    this.templates.entertainment = [
      {
        type: 'animation',
        id: 'dynamic-intro',
        timing: { start: 0, duration: 1.5 },
        properties: { type: 'æ—‹è½¬ç™»åœº', intensity: 'high' }
      },
      {
        type: 'transition',
        id: 'flashy-cuts',
        timing: { start: 0, duration: 0.3 },
        properties: { type: 'å…‰æ™•è¿‡æ¸¡', energy: 'high' }
      }
    ];

    // ç¤¾äº¤åª’ä½“é£æ ¼æ¨¡æ¿
    this.templates.social = [
      {
        type: 'text',
        id: 'hashtag-overlay',
        timing: { start: 1, duration: 2 },
        properties: {
          text: '#{{title}} #RanJok',
          fontSize: 28,
          color: '#ff6b6b',
          position: 'bottom',
          animation: 'å¼¹è·³æ•ˆæœ'
        }
      },
      {
        type: 'filter',
        id: 'social-pop',
        timing: { start: 0, duration: -1 },
        properties: { type: 'å¤å¤èƒ¶ç‰‡', strength: 0.5 }
      }
    ];
  }

  private initializeMusicLibrary() {
    this.musicLibrary = {
      upbeat: [
        './material/upbeat-energy.mp3',
        './material/happy-pop.mp3',
        './material/modern-electronic.mp3'
      ],
      calm: [
        './material/peaceful-piano.mp3',
        './material/ambient-nature.mp3',
        './material/soft-guitar.mp3'
      ],
      dramatic: [
        './material/epic-orchestral.mp3',
        './material/cinematic-tension.mp3',
        './material/powerful-drums.mp3'
      ],
      corporate: [
        './material/professional-business.mp3',
        './material/modern-corporate.mp3',
        './material/inspiring-growth.mp3'
      ]
    };
  }

  async generateVideoWithJianYing(config: EnhancedAutoVideoConfig): Promise<JianYingWorkflowResult> {
    const workflowSteps: Array<{ step: string; success: boolean; result?: any; error?: string }> = [];
    
    try {
      console.log('ğŸ¬ å¼€å§‹ä½¿ç”¨å‰ªæ˜ MCPç”Ÿæˆè§†é¢‘...');
      
      // ç¡®ä¿å‰ªæ˜ MCPå·²å¯åŠ¨
      if (!jianYingMCP.isReady()) {
        console.log('ğŸš€ å¯åŠ¨å‰ªæ˜ MCPæœåŠ¡å™¨...');
        await jianYingMCP.startMCPServer();
      }

      // æ­¥éª¤1: è·å–åˆ¶ä½œè§„èŒƒ
      console.log('ğŸ“‹ è·å–å‰ªæ˜ åˆ¶ä½œè§„èŒƒ...');
      const rules = await jianYingMCP.getRules();
      workflowSteps.push({
        step: 'è·å–åˆ¶ä½œè§„èŒƒ',
        success: rules.success,
        result: rules.result,
        error: rules.error
      });

      // æ­¥éª¤2: åˆ†ææºè§†é¢‘æ–‡ä»¶
      console.log('ğŸ“Š åˆ†ææºè§†é¢‘æ–‡ä»¶...');
      const analyzedClips = await this.analyzeSourceClipsWithMCP(config.sourceClips);
      workflowSteps.push({
        step: 'åˆ†ææºè§†é¢‘æ–‡ä»¶',
        success: analyzedClips.length > 0,
        result: { clipCount: analyzedClips.length }
      });

      // æ­¥éª¤3: åˆ›å»ºè‰ç¨¿é¡¹ç›®
      console.log('ğŸ“ åˆ›å»ºå‰ªæ˜ è‰ç¨¿é¡¹ç›®...');
      const draftConfig: DraftConfig = {
        name: config.title,
        resolution: config.aspectRatio === '16:9' ? '1080p' : '720p',
        frame_rate: 30,
        duration: config.targetDuration
      };
      
      const draftResult = await jianYingMCP.createDraft(draftConfig);
      if (!draftResult.success || !draftResult.draft_id) {
        throw new Error(`åˆ›å»ºè‰ç¨¿å¤±è´¥: ${draftResult.error}`);
      }
      
      workflowSteps.push({
        step: 'åˆ›å»ºè‰ç¨¿é¡¹ç›®',
        success: draftResult.success,
        result: { draftId: draftResult.draft_id }
      });

      const draftId = draftResult.draft_id;
      const trackIds: Record<string, string> = {};

      // æ­¥éª¤4: åˆ›å»ºè½¨é“
      console.log('ğŸ›¤ï¸  åˆ›å»ºè§†é¢‘è½¨é“...');
      const videoTrackResult = await jianYingMCP.createTrack({
        draft_id: draftId,
        track_type: 'video',
        track_name: 'main_video'
      });
      
      if (videoTrackResult.success && videoTrackResult.track_id) {
        trackIds.video_1 = videoTrackResult.track_id;
      }

      // åˆ›å»ºéŸ³é¢‘è½¨é“
      console.log('ğŸ›¤ï¸  åˆ›å»ºéŸ³é¢‘è½¨é“...');
      const audioTrackResult = await jianYingMCP.createTrack({
        draft_id: draftId,
        track_type: 'audio',
        track_name: 'background_music'
      });
      
      if (audioTrackResult.success && audioTrackResult.track_id) {
        trackIds.audio_1 = audioTrackResult.track_id;
      }

      // åˆ›å»ºæ–‡æœ¬è½¨é“
      console.log('ğŸ›¤ï¸  åˆ›å»ºæ–‡æœ¬è½¨é“...');
      const textTrackResult = await jianYingMCP.createTrack({
        draft_id: draftId,
        track_type: 'text',
        track_name: 'titles_captions'
      });
      
      if (textTrackResult.success && textTrackResult.track_id) {
        trackIds.text_1 = textTrackResult.track_id;
      }

      workflowSteps.push({
        step: 'åˆ›å»ºè½¨é“',
        success: Object.keys(trackIds).length > 0,
        result: { trackIds }
      });

      // æ­¥éª¤5: æ™ºèƒ½å‰ªè¾‘å’Œæ·»åŠ è§†é¢‘ç‰‡æ®µ
      console.log('âœ‚ï¸  æ™ºèƒ½å‰ªè¾‘å¹¶æ·»åŠ è§†é¢‘ç‰‡æ®µ...');
      const selectedClips = await this.intelligentClipSelection(analyzedClips, config);
      const segmentIds: string[] = [];
      
      let currentTime = 0;
      for (let i = 0; i < selectedClips.length && trackIds.video_1; i++) {
        const clip = selectedClips[i];
        const segmentDuration = Math.min(clip.duration, config.targetDuration - currentTime);
        
        if (segmentDuration <= 0) break;

        const videoSegmentConfig: VideoSegmentConfig = {
          draft_id: draftId,
          track_id: trackIds.video_1,
          material: clip.filePath,
          target_start_end: `${currentTime}-${currentTime + segmentDuration}`,
          source_start_end: `${clip.startTime}-${clip.startTime + segmentDuration}`,
          speed: 1.0,
          volume: 0.8 // é™ä½åŸå§‹éŸ³é¢‘éŸ³é‡
        };

        const segmentResult = await jianYingMCP.addVideoSegment(videoSegmentConfig);
        if (segmentResult.success && segmentResult.segment_id) {
          segmentIds.push(segmentResult.segment_id);
        }

        currentTime += segmentDuration;
      }

      workflowSteps.push({
        step: 'æ·»åŠ è§†é¢‘ç‰‡æ®µ',
        success: segmentIds.length > 0,
        result: { segmentCount: segmentIds.length }
      });

      // æ­¥éª¤6: æ·»åŠ èƒŒæ™¯éŸ³ä¹
      if (config.musicStyle && trackIds.audio_1) {
        console.log('ğŸµ æ·»åŠ èƒŒæ™¯éŸ³ä¹...');
        const musicFiles = this.musicLibrary[config.musicStyle];
        const selectedMusic = musicFiles[Math.floor(Math.random() * musicFiles.length)];
        
        const audioSegmentConfig: AudioSegmentConfig = {
          draft_id: draftId,
          track_id: trackIds.audio_1,
          material: selectedMusic,
          target_start_end: `0-${currentTime}`,
          volume: 0.3,
          fade_in: 2,
          fade_out: 2
        };

        const musicResult = await jianYingMCP.addAudioSegment(audioSegmentConfig);
        workflowSteps.push({
          step: 'æ·»åŠ èƒŒæ™¯éŸ³ä¹',
          success: musicResult.success,
          result: { musicFile: selectedMusic }
        });
      }

      // æ­¥éª¤7: æ·»åŠ æ ‡é¢˜å’Œå­—å¹•
      if (trackIds.text_1) {
        console.log('ğŸ“ æ·»åŠ æ ‡é¢˜æ–‡æœ¬...');
        
        // æ·»åŠ ä¸»æ ‡é¢˜
        const titleConfig: TextSegmentConfig = {
          draft_id: draftId,
          track_id: trackIds.text_1,
          content: config.title,
          target_start_end: '2-5',
          font_size: this.getStyleFontSize(config.style),
          font_color: this.getStyleFontColor(config.style),
          position: 'center',
          animation: this.getStyleAnimation(config.style)
        };

        const titleResult = await jianYingMCP.addTextSegment(titleConfig);
        
        // æ·»åŠ å­—å¹•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if (config.includeCaptions) {
          const segments = Math.floor(currentTime / 5); // æ¯5ç§’ä¸€ä¸ªå­—å¹•
          for (let i = 0; i < segments; i++) {
            const captionConfig: TextSegmentConfig = {
              draft_id: draftId,
              track_id: trackIds.text_1,
              content: `å­—å¹•å†…å®¹ ${i + 1}`,
              target_start_end: `${i * 5}-${(i + 1) * 5}`,
              font_size: 24,
              font_color: '#ffffff',
              position: 'bottom'
            };

            await jianYingMCP.addTextSegment(captionConfig);
          }
        }

        workflowSteps.push({
          step: 'æ·»åŠ æ–‡æœ¬å†…å®¹',
          success: titleResult.success,
          result: { captionsEnabled: config.includeCaptions }
        });
      }

      // æ­¥éª¤8: åº”ç”¨é£æ ¼ç‰¹æ•ˆ
      console.log('âœ¨ åº”ç”¨é£æ ¼ç‰¹æ•ˆ...');
      const templateEffects = this.templates[config.style] || this.templates.vlog;
      const effectResults = [];

      for (const effect of templateEffects) {
        if (effect.type === 'filter' && segmentIds.length > 0) {
          // åº”ç”¨æ»¤é•œåˆ°ç¬¬ä¸€ä¸ªè§†é¢‘ç‰‡æ®µ
          const filterConfig: EffectConfig = {
            draft_id: draftId,
            segment_id: segmentIds[0],
            effect_type: 'filter',
            effect_name: effect.properties.type,
            parameters: {
              strength: effect.properties.strength || 0.5
            }
          };

          const filterResult = await jianYingMCP.addEffect(filterConfig);
          effectResults.push(filterResult);
        }
        
        // å¯ä»¥æ·»åŠ æ›´å¤šç‰¹æ•ˆç±»å‹çš„å¤„ç†
      }

      workflowSteps.push({
        step: 'åº”ç”¨é£æ ¼ç‰¹æ•ˆ',
        success: effectResults.some(r => r.success),
        result: { effectCount: effectResults.length }
      });

      // æ­¥éª¤9: å¯¼å‡ºé¡¹ç›®
      console.log('ğŸ“¤ å¯¼å‡ºå‰ªæ˜ é¡¹ç›®...');
      const exportResult = await jianYingMCP.exportDraft(draftId, config.title);
      
      workflowSteps.push({
        step: 'å¯¼å‡ºé¡¹ç›®',
        success: exportResult.success,
        result: exportResult.result
      });

      // æ„å»ºè¿”å›ç»“æœ
      const timeline = selectedClips.slice(0, segmentIds.length);
      const effects = this.convertTemplateEffectsToVideoEffects(templateEffects, config);

      return {
        success: true,
        draftId,
        trackIds,
        segmentIds,
        exportPath: exportResult.result?.output_path || config.exportPath,
        timeline,
        effects,
        estimatedDuration: currentTime,
        workflowSteps
      };

    } catch (error) {
      console.error('âŒ å‰ªæ˜ MCPè§†é¢‘ç”Ÿæˆå¤±è´¥:', error);
      
      workflowSteps.push({
        step: 'é”™è¯¯å¤„ç†',
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error'
      });

      return {
        success: false,
        trackIds: {},
        segmentIds: [],
        timeline: [],
        effects: [],
        estimatedDuration: 0,
        workflowSteps
      };
    }
  }

  private async analyzeSourceClipsWithMCP(filePaths: string[]): Promise<VideoClip[]> {
    const clips: VideoClip[] = [];
    
    for (let i = 0; i < filePaths.length; i++) {
      const filePath = filePaths[i];
      
      try {
        // ä½¿ç”¨å‰ªæ˜ MCPè§£æåª’ä½“ä¿¡æ¯
        const mediaInfo = await jianYingMCP.parseMediaInfo(filePath);
        
        if (mediaInfo.success && mediaInfo.result) {
          clips.push({
            id: `clip_${i + 1}`,
            filePath,
            duration: mediaInfo.result.duration || 30,
            startTime: 0,
            endTime: mediaInfo.result.duration || 30,
            metadata: {
              width: 1920,
              height: 1080,
              fps: mediaInfo.result.frame_rate || 30,
              bitrate: 8000
            }
          });
        }
      } catch (error) {
        console.warn(`âš ï¸  æ— æ³•åˆ†ææ–‡ä»¶ ${filePath}:`, error);
        // ä½¿ç”¨é»˜è®¤å€¼
        clips.push({
          id: `clip_${i + 1}`,
          filePath,
          duration: 30,
          startTime: 0,
          endTime: 30,
          metadata: {
            width: 1920,
            height: 1080,
            fps: 30,
            bitrate: 8000
          }
        });
      }
    }

    return clips;
  }

  private async intelligentClipSelection(clips: VideoClip[], config: EnhancedAutoVideoConfig): Promise<VideoClip[]> {
    const selectedClips: VideoClip[] = [];
    let totalDuration = 0;

    for (const clip of clips) {
      if (totalDuration >= config.targetDuration) break;

      // åŸºäºé£æ ¼çš„æ™ºèƒ½ç‰‡æ®µé€‰æ‹©
      const highlights = this.findHighlights(clip, config.style);
      
      for (const highlight of highlights) {
        if (totalDuration >= config.targetDuration) break;
        
        const remainingTime = config.targetDuration - totalDuration;
        const clipDuration = Math.min(highlight.duration, remainingTime);
        
        selectedClips.push({
          ...clip,
          id: `selected_${selectedClips.length + 1}`,
          startTime: highlight.startTime,
          endTime: highlight.startTime + clipDuration,
          duration: clipDuration
        });
        
        totalDuration += clipDuration;
      }
    }

    return selectedClips;
  }

  private findHighlights(clip: VideoClip, style: string): Array<{ startTime: number; duration: number; score: number }> {
    const highlights = [];
    const segmentDuration = Math.min(5, clip.duration / 3); // åŠ¨æ€ç‰‡æ®µæ—¶é•¿
    
    for (let i = 0; i < clip.duration - segmentDuration; i += segmentDuration) {
      let score = Math.random();
      
      // æ ¹æ®é£æ ¼è°ƒæ•´è¯„åˆ†
      switch (style) {
        case 'vlog':
          score *= (i < 10 || i > clip.duration - 10) ? 1.3 : 1;
          break;
        case 'business':
          score *= i < clip.duration / 2 ? 1.2 : 1;
          break;
        case 'education':
          score *= 1;
          break;
        case 'entertainment':
          score *= Math.sin(i / 10) * 0.4 + 1.2;
          break;
        case 'social':
          score *= (i < 5 || i > clip.duration - 5) ? 1.5 : 0.8;
          break;
      }

      if (score > 0.6) {
        highlights.push({
          startTime: i,
          duration: Math.min(segmentDuration, clip.duration - i),
          score
        });
      }
    }

    return highlights.sort((a, b) => b.score - a.score).slice(0, 2);
  }

  private getStyleFontSize(style: string): number {
    const fontSizes = {
      vlog: 44,
      business: 38,
      education: 40,
      entertainment: 52,
      social: 36
    };
    return fontSizes[style as keyof typeof fontSizes] || 40;
  }

  private getStyleFontColor(style: string): string {
    const colors = {
      vlog: '#ffffff',
      business: '#2c3e50',
      education: '#3498db',
      entertainment: '#ff6b6b',
      social: '#e74c3c'
    };
    return colors[style as keyof typeof colors] || '#ffffff';
  }

  private getStyleAnimation(style: string): string {
    const animations = {
      vlog: 'å¼¹è·³æ•ˆæœ',
      business: 'æ»‘åŠ¨è¿›å…¥',
      education: 'ç¼©æ”¾å‡ºç°',
      entertainment: 'æ—‹è½¬ç™»åœº',
      social: 'å¼¹è·³æ•ˆæœ'
    };
    return animations[style as keyof typeof animations] || 'æ·¡å…¥æ·¡å‡º';
  }

  private convertTemplateEffectsToVideoEffects(templateEffects: VideoEffect[], config: EnhancedAutoVideoConfig): VideoEffect[] {
    return templateEffects.map((effect, index) => ({
      ...effect,
      id: `${effect.id}_${index}`,
      properties: {
        ...effect.properties,
        text: effect.properties.text?.replace('{{title}}', config.title).replace('{{index}}', '1')
      }
    }));
  }

  // æ‰¹é‡è§†é¢‘ç”Ÿæˆ
  async batchGenerateVideosWithJianYing(configs: EnhancedAutoVideoConfig[]): Promise<{
    results: Array<{
      config: EnhancedAutoVideoConfig;
      result: JianYingWorkflowResult;
      success: boolean;
      error?: string;
    }>
  }> {
    const results = [];

    console.log(`ğŸ”„ å¼€å§‹æ‰¹é‡ç”Ÿæˆ ${configs.length} ä¸ªè§†é¢‘`);

    for (const config of configs) {
      try {
        console.log(`ğŸ“¹ å¤„ç†è§†é¢‘: ${config.title}`);
        const result = await this.generateVideoWithJianYing(config);
        
        results.push({
          config,
          result,
          success: result.success
        });
      } catch (error) {
        results.push({
          config,
          result: {
            success: false,
            trackIds: {},
            segmentIds: [],
            timeline: [],
            effects: [],
            estimatedDuration: 0,
            workflowSteps: []
          },
          success: false,
          error: error instanceof Error ? error.message : 'Unknown error'
        });
      }
    }

    const successCount = results.filter(r => r.success).length;
    console.log(`âœ… æ‰¹é‡ç”Ÿæˆå®Œæˆ: ${successCount}/${configs.length} æˆåŠŸ`);

    return { results };
  }
}

export { EnhancedRanJokVideoEditor, type EnhancedAutoVideoConfig, type JianYingWorkflowResult };

// åˆ›å»ºå…¨å±€å®ä¾‹
export const enhancedVideoEditor = new EnhancedRanJokVideoEditor();